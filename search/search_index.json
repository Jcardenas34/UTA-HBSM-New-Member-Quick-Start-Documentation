{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Charged Higgs UTA Quick Start Documentation The way that this documentation is structured is in a series of links. Very many resources That I used to learn the practicle skills needed to do Particle Physics were from random internet links and not books. So very often the resource that I found most helpful, wether it be a reference document, a video series on youtube, or a tutorial outlining steps will look like this. Take the first step... It's a link to cool LO-FI music that you can listen to Take what you can from these links, and add new ones to this document if you feel youve learned more from it. Our general meetings that take place every tuesday and Friday have a page where we post our results for the week as well as a link to the video calling software that we use when we are unable to meet physically here ask us for the password to the page, as it is unwise to post it in a public place like this. For full documentation visit mkdocs.org . Works in progress All of it but specifically id like to add More about ATLAS and our charged higgs process, super symmetry and all that the ATLAS detector how to write a paper using overleaf or Latex Where to find papers group matter most Getting started with a CERN account Vidyo Common practices tools and resources people in the collaboration use like vidyo and indico","title":"Home"},{"location":"#charged-higgs-uta","text":"","title":"Charged Higgs UTA"},{"location":"#quick-start-documentation","text":"The way that this documentation is structured is in a series of links. Very many resources That I used to learn the practicle skills needed to do Particle Physics were from random internet links and not books. So very often the resource that I found most helpful, wether it be a reference document, a video series on youtube, or a tutorial outlining steps will look like this. Take the first step... It's a link to cool LO-FI music that you can listen to Take what you can from these links, and add new ones to this document if you feel youve learned more from it. Our general meetings that take place every tuesday and Friday have a page where we post our results for the week as well as a link to the video calling software that we use when we are unable to meet physically here ask us for the password to the page, as it is unwise to post it in a public place like this. For full documentation visit mkdocs.org .","title":"Quick Start Documentation"},{"location":"#works-in-progress","text":"All of it but specifically id like to add More about ATLAS and our charged higgs process, super symmetry and all that the ATLAS detector how to write a paper using overleaf or Latex Where to find papers group matter most Getting started with a CERN account Vidyo Common practices tools and resources people in the collaboration use like vidyo and indico","title":"Works in progress"},{"location":"about/","text":"HBSM Group at UTA The Need for More This documentation was created out of the necessity to get new undergraduate as well as new Graduate students ready to do research as fast as possible. At the start There was very little if any documentation on how to use critical software necessary to become a particle physicist. Such as how to use ROOT, where to find papers, where to go to learn to code in C++ and python or even how to use the Tier3 cluster here at UTA much less about what it is or where its located. It is my idea that if I can provide a central place where all of this information is located, I can expidite the progress of this group, as well as the HEP (High Energy Physics) Community here at UTA. People will come and go at UTA, but here are the current students and faculty you will become aquainted with. As a User to this documentation, I ask you, please help contribute to this document so that UTA's Physics Department can grow stonger, closer, and more competative in the coming years, by helping students who are learning, just like you, understand how to become a physicist. This documentation was made with MkDocs","title":"About"},{"location":"about/#hbsm-group-at-uta","text":"","title":"HBSM Group at UTA"},{"location":"about/#the-need-for-more","text":"This documentation was created out of the necessity to get new undergraduate as well as new Graduate students ready to do research as fast as possible. At the start There was very little if any documentation on how to use critical software necessary to become a particle physicist. Such as how to use ROOT, where to find papers, where to go to learn to code in C++ and python or even how to use the Tier3 cluster here at UTA much less about what it is or where its located. It is my idea that if I can provide a central place where all of this information is located, I can expidite the progress of this group, as well as the HEP (High Energy Physics) Community here at UTA. People will come and go at UTA, but here are the current students and faculty you will become aquainted with. As a User to this documentation, I ask you, please help contribute to this document so that UTA's Physics Department can grow stonger, closer, and more competative in the coming years, by helping students who are learning, just like you, understand how to become a physicist. This documentation was made with MkDocs","title":"The Need for More"},{"location":"coding/","text":"Coding Languages and the Command Line Everyone starts out with a diffent level of experience in coding, If you take me for example I came into the Graduate program here knowing little to nothing about how to code, just basic for loops and varible declarations. But in joining the High Energy Community you will no doubt have to become a master In 2 programming languages they are C++ and Python . Where I have linked the sources to thier documentation in the links there. But before you can embark on your jouney in learning these programming languaes, you must learn How to navigate your command line terminal This is what will let you take your first steps so to say, It is what will allow you to run the C++ and Python scripts that you write, as well as copy files to and from other computers. After you feel like you can do the very basic commands out of muscle memory, such as creating files and directories, moving and copying those files you can start learning about the coding languages we use on a daily basis, Python and C++.","title":"Command Line"},{"location":"coding/#coding-languages-and-the-command-line","text":"Everyone starts out with a diffent level of experience in coding, If you take me for example I came into the Graduate program here knowing little to nothing about how to code, just basic for loops and varible declarations. But in joining the High Energy Community you will no doubt have to become a master In 2 programming languages they are C++ and Python . Where I have linked the sources to thier documentation in the links there. But before you can embark on your jouney in learning these programming languaes, you must learn How to navigate your command line terminal This is what will let you take your first steps so to say, It is what will allow you to run the C++ and Python scripts that you write, as well as copy files to and from other computers. After you feel like you can do the very basic commands out of muscle memory, such as creating files and directories, moving and copying those files you can start learning about the coding languages we use on a daily basis, Python and C++.","title":"Coding Languages and the Command Line"},{"location":"github/","text":"Getting Started with Github Git hub, is a way for you to store your files on free online cloud server, as well as a way for multiple people to make changes to the same piece of software. Lots of Groups in ATLAS use github because that have many members that need to work towards the same project. Lets say that there is a big project that needs to be worked on that has multiple sections, Some people work on a graphical user interface, some on key user functions and other on making the program handicap compatible. It is impossible for one team to work on all of these components at once so the work is split into groups so that each group works on a major component, but in the end all components are combined to give you a final working product. This is where github becomes useful. If there is a physics project that you need to work on with someone, you can create a git repository (A place to store the code on the github website) where you can both download an intial version of the code, work on it and then push it back to a \"master\" file at the end of the day. So thats it for an introduction, I think this video series is pretty good at explaining what git and github is and how to use it. Learn Git/Github here","title":"Github"},{"location":"github/#getting-started-with-github","text":"Git hub, is a way for you to store your files on free online cloud server, as well as a way for multiple people to make changes to the same piece of software. Lots of Groups in ATLAS use github because that have many members that need to work towards the same project. Lets say that there is a big project that needs to be worked on that has multiple sections, Some people work on a graphical user interface, some on key user functions and other on making the program handicap compatible. It is impossible for one team to work on all of these components at once so the work is split into groups so that each group works on a major component, but in the end all components are combined to give you a final working product. This is where github becomes useful. If there is a physics project that you need to work on with someone, you can create a git repository (A place to store the code on the github website) where you can both download an intial version of the code, work on it and then push it back to a \"master\" file at the end of the day. So thats it for an introduction, I think this video series is pretty good at explaining what git and github is and how to use it. Learn Git/Github here","title":"Getting Started with Github"},{"location":"neuralnets/","text":"Getting Started with Neural Networks As of today, the field of particle physics is moving towards the use of Neural Networks to help us as particle physicists do our job. They are quickly showing they can out perform the previous data analysis tool called the Boosted Decision Tree (BDT), When It comes to distinguishing a process that we are looking for from something that we arent, since they ofentimes look similar and can be confused. The resource that I suggest using to learn about neural networks is the series by 3 blue 1 brown, here He has created a somewhat easy to follow series of videos that give you a basic idea of how a neural networks functions, as well as gets you familiar with some of the jargon. At the time of this writing, there are 4 videos, so make sure to watch them all.","title":"Neural Networks"},{"location":"neuralnets/#getting-started-with-neural-networks","text":"As of today, the field of particle physics is moving towards the use of Neural Networks to help us as particle physicists do our job. They are quickly showing they can out perform the previous data analysis tool called the Boosted Decision Tree (BDT), When It comes to distinguishing a process that we are looking for from something that we arent, since they ofentimes look similar and can be confused. The resource that I suggest using to learn about neural networks is the series by 3 blue 1 brown, here He has created a somewhat easy to follow series of videos that give you a basic idea of how a neural networks functions, as well as gets you familiar with some of the jargon. At the time of this writing, there are 4 videos, so make sure to watch them all.","title":"Getting Started with Neural Networks"},{"location":"python/","text":"Python and C++ our Main Programming Languages There are certian programming languages that people use for differnt project types, for example, if you were to try and build a website you might want to learn to code in HTML or if you were in Data science it might be useful to learn the R programming language. It just so happens that in Particle physics, the 2 programming languages that are most useful to us are C++ and Python. C++ for its speed in large projects and compatability with ROOT (Which youll learn about later), and Python, for its ease of use, compatability with common machine learning software such as Keras and Tensorflow as well as its increaced simplicity when using ROOT. Like I said previously, Its very useful to get to a working proficiency with both languages but our group has recently trasitioned to working with Python, as it is easier to use with ROOT, and for our Neural Network projects. So where can you learn how to code in these languages? Some of the youtube series that helped me get familiar with Python are here and C++ here Dont get me wrong, these series of videos are VERY long, and will take a while to get through them, but by the end you will have a better understanding of how to write code in these languages. And please, dont feel like you have to watch these videos sequentially from start to finish, skip around and watch the ones you have questions about.","title":"Python"},{"location":"python/#python-and-c-our-main-programming-languages","text":"There are certian programming languages that people use for differnt project types, for example, if you were to try and build a website you might want to learn to code in HTML or if you were in Data science it might be useful to learn the R programming language. It just so happens that in Particle physics, the 2 programming languages that are most useful to us are C++ and Python. C++ for its speed in large projects and compatability with ROOT (Which youll learn about later), and Python, for its ease of use, compatability with common machine learning software such as Keras and Tensorflow as well as its increaced simplicity when using ROOT. Like I said previously, Its very useful to get to a working proficiency with both languages but our group has recently trasitioned to working with Python, as it is easier to use with ROOT, and for our Neural Network projects. So where can you learn how to code in these languages? Some of the youtube series that helped me get familiar with Python are here and C++ here Dont get me wrong, these series of videos are VERY long, and will take a while to get through them, but by the end you will have a better understanding of how to write code in these languages. And please, dont feel like you have to watch these videos sequentially from start to finish, skip around and watch the ones you have questions about.","title":"Python and C++ our Main Programming Languages"},{"location":"root/","text":"Everything ROOT As you have probably already realized, Doing physics has a lot of prerequisites. You have to learn a LOT of stuff before you can start doing actual research. But this tool, ROOT is the primary one that we use in the High energy physics communuty. It is used to","title":"ROOT"},{"location":"root/#everything-root","text":"As you have probably already realized, Doing physics has a lot of prerequisites. You have to learn a LOT of stuff before you can start doing actual research. But this tool, ROOT is the primary one that we use in the High energy physics communuty. It is used to","title":"Everything ROOT"},{"location":"tier3/","text":"The Tier3: The High Energy Physics (HEP) Cluster If you stay in the computing world it is more than likely youll run into a situation where youll have to use a computer cluster. These computer clusters are used when you have a piece of code that requires a lot of computing resources such as the need to run on multiple processors or requires much more RAM than one computer can provide. A lot of the time in High Energy Physics we create such pieces of code. The computing cluster that we have access to in the High Energy Physics (HEP) department is called the Tier3. It is part of 3 clusters associated with the LHC (Tier1, tier2, and Tier3), and certian universities host them, we are one of them. The tier3 is what does all the computation for analysis, the others have other dedicated processes. There are other computing clusters that CERN uses, such as the GRID and lxplus, but from day to day since the tier3 is located on campus, you will be using this most of the time. In general the way that clusters are structured is as such, The Head node This is the computer that you or any person who wants to access the cluster logs into via \"ssh\". If you have not logged into the tier3 yet, you will have to contact the cluster manager at UTA, at the time of writing this is Mark Sosebee: sosebee@exchange.uta.edu who will create an account for you and give you instructions on how to log in. Here is the basic command that you will use at your command line to login to the tier3 ssh -X <user_name>@master.tier3-ATLAS.uta.edu This Head node, is where you will be doing most of your work, and where you will submit your code to what we call a batch scheduler that will effectively run your code. The Batch schedueler is the program that distributes your job to the rest of the computers connected to the head node, called the compute nodes and tells them to run the script you are writing, there are many types of bactch scheduelers that different clusters use, some popular ones are \"Slurm\", named after the famous drink in futurama, Condor which is used by the lxplus cluster that CERN uses and PBS (Portable Batch Schedueler) which we use on the tier3. Each one of these batch scheduelers has a set of commands you can type to give you information on the current jobs that are runnning on the cluster as well as commands that will submit your code to the cluster such as \"qsub\". BUT, In order to make the compute nodes process your code, instead of typing out \"qsub script_you_want_to_run.suffix\" where suffix can be anything from .py to .cxx, you must create what we call a submission script. This is a script with a siffix of \".sub\" that lets the batch schedueler know how many processors you want to use, as well as how much RAM and compute time you need. and also contains all of the commands that you want the compute nodes to execute. There will be an example of how to write a basic submission script as well as links to the documentation on all the possible options in a section below. The Compute nodes The compute nodes are what do all of the computation in your script, and they are all connected to the head node via the batch schedueler, which as I said above determines via a submission script how many compute nodes will process your code and many other computing resources are needed. The Batch Script","title":"The Tier 3"},{"location":"tier3/#the-tier3-the-high-energy-physics-hep-cluster","text":"If you stay in the computing world it is more than likely youll run into a situation where youll have to use a computer cluster. These computer clusters are used when you have a piece of code that requires a lot of computing resources such as the need to run on multiple processors or requires much more RAM than one computer can provide. A lot of the time in High Energy Physics we create such pieces of code. The computing cluster that we have access to in the High Energy Physics (HEP) department is called the Tier3. It is part of 3 clusters associated with the LHC (Tier1, tier2, and Tier3), and certian universities host them, we are one of them. The tier3 is what does all the computation for analysis, the others have other dedicated processes. There are other computing clusters that CERN uses, such as the GRID and lxplus, but from day to day since the tier3 is located on campus, you will be using this most of the time. In general the way that clusters are structured is as such,","title":"The Tier3: The High Energy Physics (HEP) Cluster"},{"location":"tier3/#the-head-node","text":"This is the computer that you or any person who wants to access the cluster logs into via \"ssh\". If you have not logged into the tier3 yet, you will have to contact the cluster manager at UTA, at the time of writing this is Mark Sosebee: sosebee@exchange.uta.edu who will create an account for you and give you instructions on how to log in. Here is the basic command that you will use at your command line to login to the tier3 ssh -X <user_name>@master.tier3-ATLAS.uta.edu This Head node, is where you will be doing most of your work, and where you will submit your code to what we call a batch scheduler that will effectively run your code. The Batch schedueler is the program that distributes your job to the rest of the computers connected to the head node, called the compute nodes and tells them to run the script you are writing, there are many types of bactch scheduelers that different clusters use, some popular ones are \"Slurm\", named after the famous drink in futurama, Condor which is used by the lxplus cluster that CERN uses and PBS (Portable Batch Schedueler) which we use on the tier3. Each one of these batch scheduelers has a set of commands you can type to give you information on the current jobs that are runnning on the cluster as well as commands that will submit your code to the cluster such as \"qsub\". BUT, In order to make the compute nodes process your code, instead of typing out \"qsub script_you_want_to_run.suffix\" where suffix can be anything from .py to .cxx, you must create what we call a submission script. This is a script with a siffix of \".sub\" that lets the batch schedueler know how many processors you want to use, as well as how much RAM and compute time you need. and also contains all of the commands that you want the compute nodes to execute. There will be an example of how to write a basic submission script as well as links to the documentation on all the possible options in a section below.","title":"The Head node"},{"location":"tier3/#the-compute-nodes","text":"The compute nodes are what do all of the computation in your script, and they are all connected to the head node via the batch schedueler, which as I said above determines via a submission script how many compute nodes will process your code and many other computing resources are needed.","title":"The Compute nodes"},{"location":"tier3/#the-batch-script","text":"","title":"The Batch Script"}]}